<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Actividad Cap√≠tulo 1: Agente Simple con Ollama Local - Curso LangGraph</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <div id="branding">
                <h1>Curso LangGraph</h1>
            </div>
            <nav>
                <ul>
                    <li><a href="index.html">Inicio</a></li>
                    <li><a href="tabla-de-contenidos.html">Tabla de Contenidos</a></li>
                    <li><a href="faq.html">FAQ</a></li>
                    <li class="current"><a href="guia-de-estudio.html">Gu√≠a de Estudio</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="container">
        <nav class="breadcrumb">
            <ul>
                <li><a href="index.html">Inicio</a></li>
                <li><a href="tabla-de-contenidos.html">Tabla de Contenidos</a></li>
                <li><a href="capitulo1.html">Cap√≠tulo 1</a></li>
                <li>Actividad Cap√≠tulo 1</li>
            </ul>
        </nav>

        <article class="main-content chapter-content">
            <h1><emoji_code>üõ†Ô∏è</emoji_code> Actividad: Creando tu Primer Agente con Ollama Local</h1>
            <p>En esta actividad, seguiremos los pasos iniciales para configurar tu entorno y comenzar a estructurar un agente que utilice Ollama para la inteligencia artificial local. Esta gu√≠a se basa en el documento "Gu√≠a Completa: Creaci√≥n de Agente LangGraph Avanzado con Ollama" [cite: 1] y los conceptos introducidos en el Cap√≠tulo 1.</p>
            <p><strong>Objetivo:</strong> Familiarizarse con la instalaci√≥n de Ollama, la configuraci√≥n del entorno Python y la estructura inicial de un agente LangGraph.</p>

            <section id="requisitos-previos">
                <h2>1. Requisitos Previos (Conceptual)</h2>
                <p>Antes de comenzar, es importante asegurarse de que tu sistema cumple con ciertos requisitos. Seg√∫n la gu√≠a proporcionada:</p>
                <ul>
                    <li><strong>Hardware M√≠nimo:</strong>
                        <ul>
                            <li>RAM: 8 GB (Recomendado: 16 GB, √ìptimo: 32 GB) [cite: 5]</li>
                            <li>CPU: 4 cores (Recomendado: 8 cores, √ìptimo: 16+ cores) [cite: 5]</li>
                            <li>Almacenamiento: 10 GB libres (Recomendado: 20 GB libres, √ìptimo: 50 GB libres) [cite: 5]</li>
                            <li>GPU: No requerida (Opcional para mejor rendimiento, ej. NVIDIA GTX 1060+ o RTX 4090) [cite: 5]</li>
                        </ul>
                    </li>
                    <li><strong>Software:</strong>
                        <ul>
                            <li>Sistema Operativo: Windows 10/11, macOS 10.15+, Linux Ubuntu 18.04+ [cite: 6]</li>
                            <li>Python: 3.8 o superior (Recomendado: 3.10+) [cite: 6]</li>
                            <li>Conexi√≥n a Internet (para descargas) [cite: 7]</li>
                        </ul>
                    </li>
                </ul>
                <p>La gu√≠a tambi√©n sugiere modelos de Ollama seg√∫n el hardware disponible[cite: 8]:</p>
                <ul>
                    <li>8 GB RAM: phi3:mini (~2.3 GB) [cite: 8]</li>
                    <li>16 GB RAM: phi4:latest (~7.4 GB) (Recomendado por la gu√≠a) [cite: 8]</li>
                    <li>32 GB+ RAM: llama2:70b (~39 GB) [cite: 8]</li>
                </ul>
            </section>

            <section id="instalacion-ollama">
                <h2>2. Instalaci√≥n y Configuraci√≥n de Ollama</h2>
                <p>Sigue estos pasos para instalar y configurar Ollama en tu sistema, como se detalla en la gu√≠a[cite: 1]:</p>
                <ol>
                    <li><strong>Descargar Ollama:</strong>
                        <ul>
                            <li>Windows: Ve a <a href="http://ollama.ai" target="_blank">ollama.ai</a>, descarga y ejecuta el instalador `OllamaSetup.exe`[cite: 9].</li>
                            <li>macOS: Usa Homebrew (`brew install ollama`) o descarga directa desde <a href="http://ollama.ai" target="_blank">ollama.ai</a>[cite: 9].</li>
                            <li>Linux: Usa el script de instalaci√≥n (`curl -fsSL https://ollama.ai/install.sh | sh`) o el gestor de paquetes de tu distribuci√≥n (ej. `yay -S ollama` para Arch Linux)[cite: 9].</li>
                        </ul>
                    </li>
                    <li><strong>Inicializar Ollama:</strong> Abre una terminal y ejecuta `ollama serve`[cite: 10]. Deber√≠as ver un mensaje indicando que Ollama est√° corriendo en `http://localhost:11434`[cite: 10].</li>
                    <li><strong>Descargar un Modelo:</strong> En una nueva terminal, descarga el modelo recomendado (u otro seg√∫n tu hardware). Por ejemplo, para `phi4:latest`[cite: 10]:
                        <pre><code class="language-bash">ollama pull phi4:latest</code></pre>
                        <p>La gu√≠a tambi√©n menciona `phi3:mini`, `llama2:latest`, y `mistral:latest` como alternativas[cite: 10].</p>
                    </li>
                    <li><strong>Probar el Modelo:</strong> En la terminal, ejecuta `ollama run phi4:latest` (o el modelo que hayas descargado)[cite: 11]. Prueba con un saludo como "Hola, ¬øpuedes ayudarme con archivos?" y espera una respuesta coherente[cite: 11]. Escribe `/bye` para salir[cite: 12].</li>
                </ol>
            </section>

            <section id="configuracion-python">
                <h2>3. Configuraci√≥n del Entorno Python</h2>
                <p>Ahora, configuremos el entorno de Python para nuestro proyecto de agente[cite: 1]:</p>
                <ol>
                    <li><strong>Verificar Python:</strong> Aseg√∫rate de tener Python 3.8+ (idealmente 3.10+)[cite: 14].
                        <pre><code class="language-bash">python --version</code></pre>
                    </li>
                    <li><strong>Crear Estructura de Proyecto:</strong> Crea un directorio para tu proyecto, por ejemplo[cite: 14]:
                        <pre><code class="language-bash">mkdir -p D:\AGENTES\agente_001_filesystem
cd D:\AGENTES\agente_001_filesystem</code></pre>
                        <p>(Ajusta la ruta seg√∫n tu sistema operativo y preferencias, ej. `~/AGENTES/agente_001_filesystem` en Linux/macOS [cite: 14]).</p>
                    </li>
                    <li><strong>Crear Entorno Virtual:</strong> Dentro del directorio de tu proyecto[cite: 14]:
                        <pre><code class="language-bash">python -m venv venv</code></pre>
                        Act√≠valo:
                        <ul>
                            <li>Windows: `venv\Scripts\activate` [cite: 14]</li>
                            <li>Linux/macOS: `source venv/bin/activate` [cite: 14]</li>
                        </ul>
                        Deber√≠as ver `(venv)` al inicio de tu terminal.
                    </li>
                    <li><strong>Crear `requirements.txt`:</strong> Crea un archivo llamado `requirements.txt` en la ra√≠z de tu proyecto con el siguiente contenido[cite: 15]:
                        <pre><code class="language-text"># Dependencias principales para el Agente LangGraph Avanzado con Ollama
langgraph&gt;=0.2.0
langchain-ollama&gt;=0.2.0
langchain-core&gt;=0.3.0

# Dependencias base (se instalan autom√°ticamente)
langchain&gt;=0.3.0
typing-extensions&gt;=4.0.0
pathlib2&gt;=2.3.0
httpx&gt;=0.25.0
requests&gt;=2.31.0

# Dependencias para manejo de datos
pandas&gt;=2.0.0
numpy&gt;=1.24.0

# Dependencias para archivos de oficina
openpyxl&gt;=3.1.0
python-docx&gt;=0.0.11 # La gu√≠a indica 0.0.11, verificar si es python-docx o docx
PyPDF2&gt;=3.0.0

# Dependencias adicionales √∫tiles
python-dateutil&gt;=2.8.0</code></pre>
                        <p><em>Nota: La gu√≠a menciona `python-docx>=0.0.11`[cite: 15]. T√≠picamente, la biblioteca es `python-docx`. Aseg√∫rate de instalar la correcta seg√∫n los mensajes de error si surgen.</em></p>
                    </li>
                    <li><strong>Instalar Dependencias</strong>[cite: 15]:
                        <pre><code class="language-bash">pip install -r requirements.txt</code></pre>
                        Puedes verificar la instalaci√≥n con `pip list | grep langgraph` (o `findstr` en Windows)[cite: 15].
                    </li>
                </ol>
            </section>

            <section id="creacion-agente-basico">
                <h2>4. Creaci√≥n del Agente B√°sico (Conceptual)</h2>
                <p>El PDF "Gu√≠a Completa: Creaci√≥n de Agente LangGraph Avanzado con Ollama" describe la creaci√≥n de un agente complejo[cite: 1]. En esta actividad inicial, nos centraremos en entender las primeras piezas del c√≥digo.</p>
                <p>Crea un archivo `advanced_filesystem_agent.py` en tu proyecto[cite: 17].</p>

                <h3>Estructura Base y Configuraci√≥n Global [cite: 17]</h3>
                <p>Al inicio de tu archivo, incluir√°s importaciones necesarias y la configuraci√≥n global para Ollama:</p>
                <pre><code class="language-python">import os
import sys
import json
# ... (otras importaciones necesarias de la gu√≠a) ...
from typing import TypedDict, List, Annotated, Dict, Any
from pathlib import Path
from datetime import datetime

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# CONFIGURACI√ìN GLOBAL DEL MODELO
OLLAMA_MODEL = "phi4:latest" # Opciones: phi3:mini, llama2:latest, mistral:latest, etc. [cite: 17]
OLLAMA_BASE_URL = "http://localhost:11434" [cite: 17]
OLLAMA_TEMPERATURE = 0.1 [cite: 17]
OLLAMA_NUM_PREDICT = 512 [cite: 17]
OLLAMA_TIMEOUT = 60 [cite: 17]
</code></pre>

                <h3>Definici√≥n del Estado del Agente [cite: 18]</h3>
                <p>Como vimos en el Cap√≠tulo 1, el estado es fundamental. La gu√≠a define un `AgentState` usando `TypedDict`[cite: 18]. Este estado se comparte entre todos los nodos[cite: 19].</p>
                <pre><code class="language-python">class AgentState(TypedDict):
    """Estado compartido entre todos los nodos del agente.""" [cite: 18]
    messages: Annotated[List, add_messages] # Historial de conversaci√≥n [cite: 20]
    current_directory: str # Directorio actual [cite: 20]
    last_operation: str # √öltima operaci√≥n realizada [cite: 20]
    operation_result: str # Resultado de la √∫ltima operaci√≥n [cite: 20]
    user_input: str # Entrada del usuario [cite: 20]
    file_context: Dict[str, Any] # Contexto de archivos para edici√≥n [cite: 20]
</code></pre>

                <h3>Clase Principal del Agente (Inicializaci√≥n)</h3>
                <p>La gu√≠a define una clase `AdvancedFileSystemAgent`[cite: 22]. El m√©todo `__init__` es crucial para configurar el LLM, directorios de trabajo y verificaciones iniciales[cite: 22].</p>
                <pre><code class="language-python">class AdvancedFileSystemAgent:
    def __init__(self):
        """Inicializar el agente con Ollama local y el grafo.""" [cite: 22]
        self.llm = ChatOllama(
            model=OLLAMA_MODEL,
            base_url=OLLAMA_BASE_URL,
            temperature=OLLAMA_TEMPERATURE,
            num_predict=OLLAMA_NUM_PREDICT,
            timeout=OLLAMA_TIMEOUT
        ) [cite: 22]

        # Directorio base y de trabajo
        self.base_directory = Path("D:/AGENTES/agente_001_filesystem") # Ajustar ruta [cite: 22]
        self.base_directory.mkdir(parents=True, exist_ok=True) [cite: 22]
        self.work_directory = self.base_directory / "workspace" [cite: 22]
        self.work_directory.mkdir(exist_ok=True) [cite: 22]
        self.current_dir = self.work_directory [cite: 22]

        self.supported_formats = {
            'text': ['.txt', '.md', '.py', '.js', '.html', '.css', '.xml', '.yml', '.yaml'],
            'office': ['.xlsx', '.docx', '.csv'],
            'data': ['.json', '.csv'],
            'pdf': ['.pdf']
        } [cite: 22]

        self._check_optional_dependencies() [cite: 22]
        self._verify_ollama_connection() [cite: 22]
        
        # El grafo se crear√° en un paso posterior
        # self.graph = self._create_graph() # [cite: 23] (Referencia al siguiente paso en el PDF)
</code></pre>
                <p>La implementaci√≥n de `_check_optional_dependencies` [cite: 25] y `_verify_ollama_connection` [cite: 25] se encuentra en las p√°ginas 12-14 de la gu√≠a[cite: 24, 25, 26]. Estas funciones ayudan a asegurar que el entorno est√© correctamente configurado antes de que el agente intente operar.</p>
            </section>

            <section id="pasos-siguientes">
                <h2>5. Pasos Siguientes (Conceptual)</h2>
                <p>La gu√≠a completa detalla muchos m√°s pasos para construir el agente avanzado, incluyendo[cite: 1]:</p>
                <ul>
                    <li>Creaci√≥n del grafo LangGraph (`_create_graph`) con nodos y flujos condicionales[cite: 26].</li>
                    <li>Implementaci√≥n de un nodo clasificador de intenciones (`_classify_intent`, `_route_based_on_intent`)[cite: 27, 28, 29, 30, 31].</li>
                    <li>Implementaci√≥n de nodos para navegaci√≥n (`_navigate_filesystem`)[cite: 32, 33, 34, 35, 36].</li>
                    <li>Implementaci√≥n de nodos para lectura multi-formato (`_read_file_advanced` y m√©todos espec√≠ficos por tipo de archivo)[cite: 38, 39, 40, 41, 42, 43, 44, 45].</li>
                    <li>Implementaci√≥n de nodos para escritura y edici√≥n (no mostrados en detalle aqu√≠ pero parte del agente avanzado)[cite: 2].</li>
                    <li>Implementaci√≥n de un nodo para generar respuestas (`_generate_response`)[cite: 26].</li>
                    <li>Una funci√≥n principal (`main`) para interactuar con el agente y scripts de prueba (`test_agent.py`)[cite: 46, 47, 48, 49, 50, 51].</li>
                </ul>
                <p>El objetivo de esta actividad introductoria es tener Ollama operativo, el entorno Python configurado con las dependencias necesarias, y una comprensi√≥n inicial de c√≥mo se estructura el archivo principal del agente y su estado. Los nodos y la l√≥gica del grafo m√°s complejos se explorar√°n en actividades o cap√≠tulos posteriores.</p>
                <p>¬°Buen trabajo al completar estos pasos iniciales!</p>
            </section>

            <div style="margin-top: 30px; display: flex; justify-content: space-between;">
                <a href="capitulo1.html" class="button">&larr; Volver al Cap√≠tulo 1</a>
                <a href="capitulo2.html" class="button">Siguiente: Cap√≠tulo 2 &rarr;</a>
            </div>

        </article>
    </div>

    <footer>
        <p>Curso de LangGraph &copy; 2025</p>
    </footer>

</body>
</html>